# PGSVD：Activation-Informed Pareto-Guided Low-Rank Compression（LLM/VLM）论文分析（理论 + 公式链 + Step 实现 + Ideas）

这篇论文提出 **PGSVD（Pareto-Guided SVD）**，核心解决一个长期痛点：**低秩压缩最难的不是“怎么做 SVD”，而是“每一层该选多大的 rank”**。既有工作常用“全层同一压缩率”或经验规则选 rank，容易导致某些层过压缩/欠压缩。PGSVD 的主要贡献是：

1. **理论**：把“层压缩误差”与“网络整体 loss 变化”建立可证明的一阶上界联系；
2. **优化视角**：把“压缩率 vs 性能损失”写成双目标（Pareto）问题，并证明：在合理鲁棒假设下，**给所有层分配同一个误差容忍度 $\varepsilon$**，会自动得到“层间异质的 ranks”，且对应**（代理意义下）Pareto 最优**；
3. **算法**：提出零样本管线：
   - 用 $\varepsilon$ 决定各层 rank；
   - 用激活感知目标 $\|WX-ABX\|_F^2$ 做 **ALS（交替最小二乘）**快速优化低秩因子；
   - VLM 场景用两个 $\varepsilon$（视觉塔/文本塔）解决跨模态差异。

------

## 1) 基线到改进：压缩目标函数如何变化

### 1.1 传统 SVD（权重空间最优）

对层权重 $W\in\mathbb{R}^{N\times M}$，低秩分解 $W\approx AB$（$A\in\mathbb{R}^{N\times r}, B\in\mathbb{R}^{r\times M}$）的经典目标是：
$$
\min_{A,B}\ \|W-AB\|_F^2
\tag{1}
$$
其最优解由截断 SVD 给出。

### 1.2 激活感知压缩（输出空间更贴近推理）

由于 LLM 某些层权重并不低秩，而激活 $X$ 往往呈低秩结构，论文主张用：
$$
\min_{A,B}\ \|WX-ABX\|_F^2
\tag{2}
$$
其中 $X$ 是该层的输入激活 batch（由校准数据获得）。这类目标是“激活驱动的重构误差”，比 $\|W-AB\|$ 更贴近推理误差。

> 这一步把“压缩做得像矩阵逼近”转为“压缩做得像在数据分布上拟合线性变换”。

------

## 2) 理论核心一：层级误差如何影响网络 loss（关键上界）

考虑一个 $L$ 层网络，层间递推：
$$
x_{l+1}=\sigma(W_l x_l)
$$
压缩后 $\hat W_l = W_l + \Delta W_l$。

论文给出一个**一阶扰动分析**结论：对于可微标量 loss $L$，存在上界：
$$
|\Delta L|
\le
G\sum_{l=1}^{L}
\Big(\prod_{m=l+1}^{L}K_m\Big)\ c\ \|\Delta W_l X_l\|_F
\tag{3}
$$
其中：

- $X_l=[x_l^{(1)}\ \cdots\ x_l^{(B)}]$ 是第 $l$ 层输入 batch；
- $c\ge \sup_t|\sigma'(t)|$ 是激活函数导数上界；
- $K_l = \sup_i \|J_l^{(i)}\|$，$J_l^{(i)}=\mathrm{diag}(\sigma'(W_lx_l^{(i)}))W_l$（后续层的 Jacobian 范数上界）；
- $G=\|\nabla_Y L\|_F$，$Y=X_{L+1}$。

**解释**：

- 层内的“局部伤害”由 $\|\Delta W_l X_l\|_F$ 衡量（这正是激活感知目标的误差项）；
- 伤害被后续层的 Jacobian 范数连乘放大/缩小；
- 最终由输出端 loss 梯度把扰动映射到 loss 变化。

这条上界是后续“Pareto rank 分配”的理论支点：

> 如果把上界当作代理目标，那么让每层的激活误差受控，就能控制整体 loss 变化。

------

## 3) 理论核心二：把 rank 选择写成双目标（Pareto）问题

### 3.1 双目标：参数量 vs loss 变化

设第 $l$ 层压缩为 rank $r_l$，全网络 rank 向量：
$$
\mathbf{r}=[r_1,\dots,r_L]
$$
总低秩参数量（每层 rank-$r_l$ 分解参数数）：
$$
S(\mathbf{r})=\sum_{l=1}^L P_l(r_l),
\quad P_l(r_l)\approx r_l(N_l+M_l)
\tag{4}
$$
网络 loss 的变化：
$$
|\Delta L(\mathbf{r})|
$$
于是双目标问题是：
$$
\min_{\mathbf{r}}\ \Big(S(\mathbf{r}),\ |\Delta L(\mathbf{r})|\Big)
\tag{B}
$$

### 3.2 用上界把双目标变成“可解的代理标量问题”

把(3)中与数据/网络相关的常数吸收成每层系数 $\alpha_l$，并把层误差用相对 Frobenius 误差写成：
$$
e_l(r_l)=\frac{\|\hat W_l^{(r_l)}-W_l\|_F}{\|W_l\|_F}
\tag{5}
$$
构造：
$$
\alpha_l=\|\nabla_Y L\|_F\Big(\prod_{m=l+1}^L K_m\Big)c\ \|X_l\|_F\ \|W_l\|_F
\tag{6}
$$
在预算 $b$ 下得到标量化代理问题：
$$
\min_{\mathbf{r}}\ \sum_{l=1}^L \alpha_l e_l(r_l)
\quad
\text{s.t. } \sum_{l=1}^L P_l(r_l)\le b
\tag{P}
$$
这可以被看作“rank 分配问题”（很像 knapsack，但层很多、候选 rank 多时不可直接穷举）。

------

## 4) 关键转化：从“选 ranks”转成“分配误差容忍度 $\varepsilon_l$”并得到闭式结构

### 4.1 定义：$\varepsilon$–参数映射（SVD profile）

对每层，给定容忍度 $\varepsilon_l\in[0,1]$，定义“满足相对误差不超过 $\varepsilon_l$”的**最小 rank**：
$$
r_l^\star(\varepsilon_l)
=\min\{r:\ e_l(r)\le \varepsilon_l\}
\tag{7}
$$
对应的最小参数量函数（profile）：
$$
h_l(\varepsilon_l)=P_l(r_l^\star(\varepsilon_l))
\tag{8}
$$
于是，rank 分配问题 (P) 等价为 $\varepsilon$ 分配问题：
$$
\min_{0\le \varepsilon_1,\dots,\varepsilon_L\le 1}
\sum_{l=1}^L \alpha_l \varepsilon_l
\quad
\text{s.t. } \sum_{l=1}^L h_l(\varepsilon_l)\le b
\tag{E}
$$
这一步非常关键：把离散的 $\{r_l\}$ 选择问题变成连续的 $\{\varepsilon_l\}$ 分配问题。

### 4.2 结论：统一 $\varepsilon$ 会自动产生异质 ranks，并落在代理 Pareto 前沿

论文在“鲁棒/保守”的设定下，用两个假设推进：

- **同质敏感度**（robust surrogate）：当 $\alpha_l$ 不确定或部署数据变化时，用统一权重近似（等价于用最大的 $\alpha$ 做 minimax-safe 代理），使目标变成 $\sum_l \varepsilon_l$；
- **profile 上下凸包有界**：各层 $h_l(\varepsilon)$ 被共同的非增凸包夹住（经验上成立，论文用大量层的 profile 图做支撑）。

在这些条件下，得到结论：

> 对任意统一容忍度 $\varepsilon$，令每层取最小 rank $r_l^\star(\varepsilon)$ 使得 $e_l(r)\le\varepsilon$，则得到的一对
> $$
> \Big(\sum_l P_l(r_l^\star(\varepsilon)),\ \sum_l \alpha_l e_l(r_l^\star(\varepsilon))\Big)
> $$
> 位于该双目标问题的**代理 Pareto 前沿**。

**直觉**：不同层的奇异谱衰减不同，因此同一个误差阈值 $\varepsilon$ 对应的最小 rank 自然不同，形成“异质压缩率”；而统一 $\varepsilon$ 则把超参搜索从 $L$ 维（每层一个 rank）降到 1 维（一个 $\varepsilon$）。

------

## 5) PGSVD 算法：从理论到可复现实现（零样本）

PGSVD 的 pipeline 可以拆成两部分：**Pareto-guided rank selection** + **Activation-aware ALS refinement**。

------

## 6) Step-by-step 实现流程（按论文 Algorithm 组织）

下面给一个对 LLM/VLM 都适用的实现顺序（逐层）：

### Step 0：准备校准激活（二阶矩即可）

对每个待压缩层 $l$ 收集该层输入激活 batch $X_l$。不一定要存全部激活，至少要得到协方差：
$$
M_l=X_lX_l^\top
\tag{9}
$$
（实现上常用累计二阶统计，避免显存爆炸。）

------

### Step 1：用统一容忍度 $\varepsilon$ 选每层 rank（Pareto-guided）

对每层权重 $W_l$：

1. 定义相对误差指标（论文用权重空间相对 Frobenius 误差来做 rank–$\varepsilon$ 映射）：

$$
e_l(r)=\frac{\|W_l-\hat W_l^{(r)}\|_F}{\|W_l\|_F}
\tag{10}
$$

其中 $\hat W_l^{(r)}$ 是 $W_l$ 的 rank-$r$ 截断 SVD 近似。

1. 选最小 rank：

$$
r_l=\min\{r\in\mathbb{Z}_{\ge0}:\ e_l(r)\le \varepsilon\}
\tag{11}
$$

> 这一步是 PGSVD 的“Pareto-guided”核心：**不是统一 rank，也不是统一压缩率，而是统一误差阈值**。

------

### Step 2：用 SVD 初始化低秩因子 $A_l,B_l$

对 $W_l$ 做 rank-$r_l$ 截断 SVD：
$$
W_l \approx U_r\Sigma_rV_r^\top
$$
初始化：
$$
A_l = U_r\Sigma_r^{1/2},\quad
B_l = \Sigma_r^{1/2}V_r^\top
\tag{12}
$$
于是 $\hat W_l=A_lB_l$。

------

### Step 3：用 ALS 直接最小化激活感知目标 $\|W_lX_l-A_lB_lX_l\|_F^2$

定义经验协方差：
$$
M_l = X_lX_l^\top
$$
ALS 的推导来自把目标写成 trace 并对 $A,B$ 求导（论文给出闭式更新）：

**更新 $A$**：
$$
A \leftarrow WMB^\top\ (BMB^\top)^{\dagger}
\tag{13}
$$
**更新 $B$**：
$$
B \leftarrow (A^\top A)^{\dagger}A^\top W
\tag{14}
$$
其中 $(\cdot)^\dagger$ 是伪逆。

循环 $\tau$ 次（论文经验：5–10 次通常就会 plateau）：
$$
(A,B)\ \xrightarrow{\text{ALS}}\ (A',B')
$$
**实现要点**：

- 伪逆只作用在 $r\times r$ 的小矩阵上（如 $BMB^\top$、$A^\top A$），所以很快；
- 用双精度做分解/伪逆更稳；
- 计算 $M$ 的前向可用全精度，避免数值崩。

------

### Step 4：写回模型（两层线性替换）

把原线性层 $y=W_lx$ 替换为：
$$
y \approx A_l(B_lx)
$$
即先做 $B_lx\in\mathbb{R}^{r_l}$，再做 $A_l(\cdot)\in\mathbb{R}^{N_l}$。

------

## 7) VLM 扩展：双塔用两个统一容忍度（$\varepsilon_t,\varepsilon_v$）

对 VLM（如文本 Transformer + ViT 图像塔），跨模态权重/梯度分布差异会导致单一 $\varepsilon$ 不公平。PGSVD 用：

- 文本塔统一 $\varepsilon_t$
- 视觉塔统一 $\varepsilon_v$

在每个塔内部仍遵循“统一 $\varepsilon$ ⇒ 异质 ranks”的逻辑。这样只需调两个超参就能适配模态差异。

------

## 8) 这篇论文相对已有激活感知 SVD 的关键差异点（方法论层面）

- 以前：多是 **统一压缩率**（每层保留同样比例 rank）或经验式 rank；
- PGSVD：把“层间 rank 分配”上升到 **双目标/Pareto**问题，并给出“统一误差容忍度”产生代理 Pareto 最优的理论支撑；
- 算法上：用 **ALS** 替代一些更易数值失败的分解步骤（并强调效率/稳定性）。

------

## 9) Ideas（不展开融合细节，仅给可写成后续工作的方向）

### Idea 1：从“鲁棒统一 $\varepsilon$”走向“分组统一 $\varepsilon$”（仍保持低维超参）

论文已提到可按类别聚类（例如 attention vs MLP、浅层 vs 深层）分配不同 $\varepsilon$。可以形式化为：
$$
\varepsilon_l = \varepsilon_{g(l)},\quad g(l)\in\{1,\dots,G\},\ G\ll L
$$
在只增加很少超参的情况下，能显著增强可控性与上界紧致度。

### Idea 2：用数据驱动估计 $\alpha_l$，从鲁棒代理回到更紧的代理 Pareto

当前“统一敏感度”是保守的。可以用少量校准数据近似 $\alpha_l$（例如估计 $K_m$、$\|X_l\|_F$、$\|\nabla_YL\|_F$ 的 proxy），让 $\varepsilon$ 分配问题变成：
$$
\min_{\varepsilon_l}\sum_l \alpha_l\varepsilon_l
\quad\text{s.t. }\sum_l h_l(\varepsilon_l)\le b
$$
并用 KKT 条件得到更接近“真实”最优的非均匀 $\varepsilon_l$（但仍可用少数超参/正则保持稳定）。

### Idea 3：把误差指标从 $\|W-\hat W\|_F$ 换成更贴近理论上界的 $\|\Delta W X\|_F$

目前 rank–$\varepsilon$ 映射用的是权重空间相对误差，而上界里真正出现的是 $\|\Delta W_lX_l\|_F$。可以考虑定义：
$$
e_l^{\text{act}}(r)=\frac{\| (W_l-\hat W_l^{(r)})X_l\|_F}{\|W_lX_l\|_F}
$$
再用统一 $\varepsilon$ 做 rank selection，可能让“理论—实现”的一致性更强。

### Idea 4：ALS 的“早停/自适应迭代次数”

不同层的目标曲线平坦程度不同。可用：
$$
\Delta_t=\frac{\mathcal{L}_{t-1}-\mathcal{L}_{t}}{\mathcal{L}_{t-1}}
$$
当 $\Delta_t<\delta$ 早停；或给难层多迭代、易层少迭代，提高整体效率。

### Idea 5：把 Pareto-guided rank selection 扩展到“多资源约束”

现实部署常同时受限于：参数量、KV cache、FLOPs、吞吐等。可扩展为：
$$
\min_{\mathbf{r}} \ \sum_l \alpha_l e_l(r_l)
\quad
\text{s.t.}\ 
\sum_l P_l(r_l)\le b_p,\ 
\sum_l C_l(r_l)\le b_c
$$
其中 $C_l$ 可表示算力/带宽 proxy，得到更贴近部署的 Pareto 前沿。