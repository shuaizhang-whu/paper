# D-Rank：Layer-wise Dynamic Rank for Compressing Large Language Models

这篇工作本质是在回答一个问题：在给定总体压缩预算（压缩率固定）的前提下，**不同层/不同矩阵的信息密度差异很大**，用统一 rank（或统一压缩率）会浪费预算、保不住关键层，于是提出一个“可计算的信息密度指标 + 拉格朗日闭式分配”的动态 rank 框架，并额外对注意力三矩阵做再平衡，适配 GQA。Mi 等 - 2025 - Layer-wise dynami…

------

## 1）基线目标：SVD 压缩在做什么（从“权重误差”到“激活加权误差”）

### 1.1 经典截断 SVD 的优化目标（权重空间）

对单个权重矩阵 $W\in\mathbb{R}^{m\times n}$，截断 SVD 对应的最优 rank-$k$ 近似：
$$
\min_{\mathrm{rank}(\widetilde W)\le k}\ \|W-\widetilde W\|_F^2
$$
最优解为 $\widetilde W=U_k\Sigma_kV_k^\top$。

但 LLM 压缩更关心的是输出误差 $(W-\widetilde W)X$，所以很多 SVD-LLM/ASVD 路线会用“激活统计”做白化/加权，让奇异值更对齐于输出误差。

### 1.2 D-Rank 沿用的激活白化思路（scaled matrix）

它把权重先做一个基于校准激活的缩放（记作 $S$），然后对缩放后的矩阵做 SVD 截断。抽象写法：
$$
W = S^{-1}(SW),\qquad SW \approx U'_k\Sigma'_kV_k'^\top
$$
从而重构：
$$
W \approx S^{-1}U'_k\Sigma'_kV_k'^\top
$$
其中 $S$ 来自校准激活 $X$ 的统计（论文写成 Cholesky 形式），本质是把“输入分布”引入分解过程，减少 outlier 放大误差。

------

## 2）问题切入点：为什么“统一 rank/统一压缩率”是次优的

D-Rank 的关键观察是：不同深度的层包含的信息密度不同（常见 U 型：中层更“满”），所以如果对所有层/所有组用同样的压缩比，就会：

- 对信息密度高的组压得太狠 → 性能掉得快
- 对信息密度低的组压得不够 → 预算浪费

因此它要做的不是发明新的 SVD，而是发明“在固定预算下如何分配每组 rank”的原则方法。

------

## 3）改进目标 1：用 effective rank 定义“信息密度”（从指标到公式）

### 3.1 分组与拼接：把跨层异质性“离散化”为 group

设模型 $N$ 层，按深度划分为 $G$ 个 group，每个 group 含 $n$ 层。对某类矩阵（例如 $W_Q$ 或 $W_V$），把同一 group 内的矩阵横向拼接：
$$
W_g = [W^{(1)},W^{(2)},\dots,W^{(n)}]\in\mathbb{R}^{d_1\times (nd_2)}
$$
再乘缩放矩阵得到 scaled matrix：
$$
\widehat W_g = S_g W_g
$$
这一步使得“组”成为 rank 分配的基本单元：对每个 $g$，分配一个 $k_g$。

### 3.2 effective rank：谱熵的指数（把奇异值分布变成一个标量）

对 scaled group matrix $\widehat W_g$ 做 SVD，奇异值为 $\{\sigma_i^g\}$。令能量（平方奇异值）：
$$
\lambda_i^g = (\sigma_i^g)^2
$$
归一化成概率分布：
$$
p_i^g = \frac{\lambda_i^g}{\sum_j \lambda_j^g}
$$
定义谱熵（Shannon entropy）：
$$
H_g = -\sum_i p_i^g \log p_i^g
$$
effective rank 定义为：
$$
R_{\mathrm{eff}}(g) = \exp(H_g)
$$
直觉：

- 若能量集中在少数奇异值（谱很尖），熵小 → $R_{\mathrm{eff}}$ 小 → 冗余大
- 若能量分布更均匀（谱更“满”），熵大 → $R_{\mathrm{eff}}$ 大 → 信息密度高

这就给了“每个 group 的信息密度”一个可计算的、与谱形状相关的标量。

------

## 4）改进目标 2：拉格朗日闭式 rank 分配（从目标函数到闭式解）

### 4.1 它实际在解的优化问题

D-Rank 设定：总体压缩率固定，等价于该模块允许保留的“rank 成本预算”固定。令：

- $k_g$：分配给 group $g$ 的保留 rank
- $\omega$：每增加 1 个 rank 的参数成本（对横向拼接后的 group，论文给 $\omega=d_1+nd_2$，可理解为 low-rank 因子 $B\in\mathbb{R}^{d_1\times k}$ 与系数 $C\in\mathbb{R}^{k\times nd_2}$ 的参数增量）
- 总预算：$T_{\text{budget}}=\sum_g k_g\omega = T(1-\theta)$，$\theta$ 为目标压缩率

它构造一个“分配不一致惩罚”：
$$
\ell_{\text{total}}=\sum_{g=1}^{G}\frac{R_{\mathrm{eff}}(g)}{k_g}
$$
并在预算约束下最小化：
$$
\min_{k_1,\dots,k_G}\ \sum_g\frac{R_{\mathrm{eff}}(g)}{k_g}
\quad \text{s.t.}\quad \sum_g k_g\omega=T_{\text{budget}}
$$
这个目标的含义可以理解为：信息密度越高（$R_{\mathrm{eff}}$ 越大）的 group，如果给的 rank 太小，会产生更大惩罚；给更多 rank 可降低惩罚。

### 4.2 拉格朗日求解与闭式比例规律

构造拉格朗日函数：
$$
F(\{k_g\},\lambda)=\sum_g\frac{R_{\mathrm{eff}}(g)}{k_g}+\lambda\left(\sum_g k_g\omega -T_{\text{budget}}\right)
$$
对 $k_g$ 求导并令 0：
$$
\frac{\partial F}{\partial k_g}=-\frac{R_{\mathrm{eff}}(g)}{k_g^2}+\lambda\omega=0
$$
得到比例关系：
$$
k_g \propto \sqrt{\frac{R_{\mathrm{eff}}(g)}{\omega}}
$$
把预算代入得到闭式分配：
$$
k_g=
\frac{T_{\text{budget}}}{\sum_{j=1}^G\sqrt{R_{\mathrm{eff}}(j)\,\omega}}
\cdot
\frac{\sqrt{R_{\mathrm{eff}}(g)}}{\sqrt{\omega}}
$$
解释非常直接：

- $R_{\mathrm{eff}}(g)$ 越大 → 分到的 $k_g$ 越大（更“重要”的组保更多 rank）
- $\omega$ 越大（更贵）→ 分到的 $k_g$ 越小（成本高的组少给 rank）
- 且是平方根规律，不会让少数组吞掉全部预算（比线性比例更温和）

------

## 5）改进目标 3：注意力矩阵再平衡（把预算从 Q/K 转移到 V）

论文进一步发现：在注意力中，不同投影矩阵的信息密度非常不均衡——尤其 $W_V$ 的 effective rank 显著更高，而 $W_Q, W_K$ 更低。若直接按 $R_{\mathrm{eff}}$ 对 Q/K/V 各自做分配，会出现一个“不公平”现象：$W_V$ 需要更多容量但在一些设定下仍可能被分得不够。

于是它引入一个超参 $\beta\in[0,1]$，把一部分 rank 预算从 Q 和 K 挪给 V。

设按拉格朗日先得到每个 group 的分配（例如共有 4 个 group）：
$$
L_Q=[k_1^Q,k_2^Q,k_3^Q,k_4^Q],\quad
L_K=[k_1^K,k_2^K,k_3^K,k_4^K],\quad
L_V=[k_1^V,k_2^V,k_3^V,k_4^V]
$$
再做再分配：
$$
L_Q^{\text{final}}=(1-\beta)L_Q
$$
把抽走的总量平均补到 $V$ 上：
$$
t=\frac{\beta}{4}\left(\sum_{i=1}^4 k_i^Q+\sum_{i=1}^4 k_i^K\right)
$$
直觉：把“冗余更高”的 Q/K 的容量转移给“信息密度更高”的 V，以更好地保留表示能力。

------

## 6）对 GQA（Grouped-Query Attention）的处理：为什么跨层拼接（basis sharing）会失效

很多 cross-layer joint SVD（例如把多层拼接做一次 SVD）在 MHA 上有效，但在 GQA（如 LLaMA-3）上反而变差。论文解释的要点是：

- GQA 的 $W_K, W_V$ 维度更“瘦”（列维更小），多层横向拼接后矩阵列维暴涨，整体 rank 可能变得更大；在固定压缩率下，拼接后截断误差更大。
- 同时，“拼接 n>1 层做联合 SVD”会导致平均到每层的有效 rank 变少（同一预算被更大矩阵吞掉），等价于对每层更激进压缩，造成性能显著劣化。

因此在 GQA 上它建议把 group size 设为 $n=1$，不做多层拼接，而是：

1. 仍用 effective rank 做层级动态 rank（这时 group 就是单层）
2. 仍做 Q/K→V 的预算再分配

------

## 7）完整 Step 实现过程（你复现时可以照这个顺序写）

下面给一个贴近工程实现的流程，按“输入→输出”讲清楚：

### Step 0：选择校准集与收集激活

用少量样本（例如 256 条、长序列）跑 forward，收集每层输入激活 $X$，并从 $X$ 构造缩放矩阵 $S$（Cholesky/白化形式）。

### Step 1：决定分组策略

- MHA 模型：可尝试 $n>1$ 层为一组做横向拼接（按论文设定可对 Q/K/V、up、gate 等做分组；对 $W_O$、$W_{down}$ 等可不分组）
- GQA 模型：直接设 $n=1$

### Step 2：构造 scaled group matrix

对每个 group $g$：

1. 横向拼接得到 $W_g$
2. 左乘缩放得到 $\widehat W_g=S_gW_g$

### Step 3：计算 effective rank（信息密度）

对每个 $\widehat W_g$：

1. 做 SVD 得 $\{\sigma_i^g\}$
2. 得概率 $p_i^g$
3. 得 $R_{\mathrm{eff}}(g)=\exp(-\sum p\log p)$

### Step 4：拉格朗日闭式分配 rank

给定目标压缩率 $\theta$，得到 $T_{\text{budget}}=T(1-\theta)$，按闭式解计算每个 $k_g$。

### Step 5：注意力再平衡（可选但论文认为有效）

对 Q/K/V 三类矩阵分别得到 $L_Q,L_K,L_V$ 后，用 $\beta$ 把 Q/K 的一部分预算转给 V，得到最终 $L_Q^{\text{final}},L_K^{\text{final}},L_V^{\text{final}}$。

### Step 6：按每个 group 的 $k_g$ 做 truncated SVD 压缩并回代

对每个 $\widehat W_g$ 做截断 SVD（保留 $k_g$），再左乘 $S_g^{-1}$ 还原到 $W_g$ 的权重空间，最后把 group 内的权重切分回各层各矩阵。

### Step 7：高压缩率时的误差累积处理（可选）

论文提到当压缩率较大时会发生层间输入偏移，可用类似 SVD-LLM 的“下游层权重更新”来适应偏移输入（闭式更新/逐层修正这一类）。

------

## 8）这篇论文“理论贡献点”用一句话概括

它并不改变 SVD 的基本形式，而是提出：

1. 用谱熵指数 $R_{\mathrm{eff}}$ 衡量每组矩阵的信息密度
2. 在固定预算下，用一个可解析的目标 $\sum R_{\mathrm{eff}}/k$ 推导出闭式 rank 分配 $k_g\propto \sqrt{R_{\mathrm{eff}}/\omega}$
3. 在注意力中做 Q/K→V 的预算再平衡，并对 GQA 给出分组策略修正

------

## 9）一些可以继续往前推的 idea（不展开结合细节，只给“可写成新方法”的方向）

1. 把“分配目标 $\sum R_{\mathrm{eff}}/k$”换成更直接的“截断误差代理”
    目前的 $\ell_{\text{total}}$ 是启发式形式。你可以定义每个 group 的截断残差能量：

$$
E_g(k)=\sum_{i>k} (\sigma_i^g)^2
$$

并做预算约束下最小化 $\sum_g E_g(k_g)$，得到更贴近真实 truncation loss 的分配理论（也更容易和 activation-aware 的误差度量对齐）。

1. 让 $\beta$ 不再是固定超参，而是由“Q/K/V 的信息密度差”自适应决定
    例如：

$$
\beta = \mathrm{clip}\left(\gamma\cdot \frac{\overline{R_{\mathrm{eff}}(V)}-\overline{R_{\mathrm{eff}}(Q,K)}}{\overline{R_{\mathrm{eff}}(V)}},\,0,\,1\right)
$$

从而把“经验调参”变成“指标驱动”的自动策略。

1. 从“层组 rank”升级到“矩阵内 rank（奇异方向）”的更细粒度预算
    现在是按 group 分配一个 $k_g$。你可以进一步在同一矩阵内部，对奇异方向做二次分配/筛选（例如结合梯度/Fisher 或 teacher-student 误差信号），把“保留哪些奇异方向”理论化。
2. 做 token-wise / stage-wise 动态 rank（生成早期保真、后期省算）
    D-Rank 是 layer-wise 静态分配。可以加一个随 decoding step $t$ 变化的预算 $T_{\text{budget}}(t)$，在不改变公式结构的前提下得到：

$$
k_g(t)=\frac{T_{\text{budget}}(t)}{\sum_j\sqrt{R_{\mathrm{eff}}(j)\omega}}\cdot \frac{\sqrt{R_{\mathrm{eff}}(g)}}{\sqrt{\omega}}
$$

把“层异质性”和“生成误差累积”统一到同一个动态预算框架里。

如果你希望我下一步更贴你的主线（SVD-LLM v2 / SAES-SVD），我可以把 D-Rank 的“effective rank + 拉格朗日分配”抽象成一个通用预算分配模块，指出它最容易嵌到哪些误差目标里、哪些地方需要替换成更严格的 truncation loss（但我这里先按你要求只做本篇的理论与步骤分析）。